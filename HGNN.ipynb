{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立User-URL二分图数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    " \n",
    "from torch_geometric.data import HeteroData, download_url, extract_zip\n",
    "from torch_geometric.transforms import ToUndirected, RandomLinkSplit\n",
    "\n",
    "# 利用pandas查看数据集\n",
    "print(pd.read_csv(movie_path).head())\n",
    "print(pd.read_csv(rating_path).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将电影名那列\n",
    "# 利用嵌入模型将每个电影名用向量表示(Embedding)\n",
    "class SequenceEncoder(object):\n",
    "    # 初始化\n",
    "    # 指定我们使用的嵌入模型\n",
    "    # 和使用的设备\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', device=None):\n",
    "        # 使用的设备\n",
    "        self.device = device\n",
    "        # 使用的嵌入模型名\n",
    "        self.model = SentenceTransformer(model_name, device=device)\n",
    " \n",
    "    # 嵌入模型不参与后续图神经网络的训练\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, df):\n",
    "        x = self.model.encode(\n",
    "            # 要进行嵌入的值\n",
    "            df.values,\n",
    "            # 显示处理进度\n",
    "            show_progress_bar=True,\n",
    "            # 转换为PyTorch的张量\n",
    "            convert_to_tensor=True,\n",
    "            # 使用的设备\n",
    "            device=self.device\n",
    "        )\n",
    "        return x.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将电影类型那列进行嵌入表示\n",
    "class GenresEncoder(object):\n",
    " \n",
    "    # 分隔符\n",
    "    def __init__(self, sep='|'):\n",
    "        self.sep = sep\n",
    " \n",
    "    def __call__(self, df):\n",
    "        # 分割出所有的电影类型\n",
    "        # 后面两个for的逻辑是：\n",
    "        # for col in df.values取出每一行的值\n",
    "        # for g in col.split(self.sep)将取出来的值用指定的分隔符进行分割\n",
    "        # set(g)将分割之后的结果转换为集合,去重\n",
    "        genres = set(g for col in df.values for g in col.split(self.sep))\n",
    "        # 将电影类型用数字表示\n",
    "        mapping = {genre: i for i, genre in enumerate(genres)}\n",
    "        # 用multi-hot形式表示电影的类型\n",
    "        x = torch.zeros(len(df), len(mapping))\n",
    "        for i, col in enumerate(df.values):\n",
    "            for genre in col.split(self.sep):\n",
    "                x[i, mapping[genre]] = 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从CSV文件中读取信息，建立二分图中节点的信息\n",
    "def load_node_csv(path, index_col, encoders=None, **kwargs):\n",
    "    \"\"\"\n",
    "    :param path: CSV文件路径\n",
    "    :param index_col: 文件中的索引列，也就是节点所在的列\n",
    "    :param encoders:节点嵌入器\n",
    "    :param kwargs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, index_col=index_col, **kwargs)\n",
    "    # 将索引用数字表示\n",
    "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
    "    # 节点属性向量矩阵\n",
    "    x = None\n",
    "    # 如果嵌入器非空\n",
    "    if encoders is not None:\n",
    "        # 对相应的列进行嵌入\n",
    "        # 获取嵌入向量表示\n",
    "        xs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
    "        x = torch.cat(xs, dim=-1)\n",
    " \n",
    "    return x, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取节点信息\n",
    "# 处理movies.csv表，将'电影名','电影类型'列转换为嵌入向量的表示形式\n",
    "movie_x, movie_mapping = load_node_csv(\n",
    "    movie_path, index_col='movieId', encoders={\n",
    "        # 电影名列的嵌入器\n",
    "        'title': SequenceEncoder(),\n",
    "        # 电影类型列的嵌入器\n",
    "        'genres': GenresEncoder()\n",
    "    })\n",
    "# 处理ratings.csv表,将用户ID用PyTorch中的张量表示\n",
    "user_x, user_mapping = load_node_csv(rating_path, index_col='userId')\n",
    "# 建立异质图（这里具体是一个二分图）\n",
    "# HeteroData()是PyG中内置的一个表示异质图的数据结构\n",
    "data = HeteroData()\n",
    "# 加入不同类型节点的信息\n",
    "# 加入用户信息，用户没有属性向量\n",
    "# 只需要告诉PyG有多少个用户节点就可以\n",
    "data['user'].num_nodes = len(user_mapping)\n",
    "# 告诉PyG 电影的属性向量矩阵，PyG会根据x推断出电影节点的个数\n",
    "data['movie'].x = movie_x\n",
    "print(data)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立用户和电影之间边的信息\n",
    "# 将用户对电影的评分转换为PyTorch中的张量\n",
    "# 方便后续模型的训练\n",
    "class IdentityEncoder(object):\n",
    " \n",
    "    def __init__(self, dtype=None):\n",
    "        self.dtype = dtype\n",
    " \n",
    "    def __call__(self, df):\n",
    "        return torch.from_numpy(df.values).view(-1, 1).to(self.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立二分图边的连接信息\n",
    "def load_edge_csv(path, src_index_col, src_mapping, dst_index_col, dst_mapping,\n",
    "                  encoders=None, **kwargs):\n",
    "    \"\"\"\n",
    "    :param path: CSV表的路径\n",
    "    :param src_index_col: 二分图左边节点来源于CSV表的哪一列，比如'user_id'这列\n",
    "    :param src_mapping:将user_id映射为节点编号，我们前面定义的user_mapping\n",
    "    :param dst_index_col:同理，二分图右边电影节点\n",
    "    :param dst_mapping:\n",
    "    :param encoders:边的嵌入器\n",
    "    :param kwargs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, **kwargs)\n",
    "    # 建立连接信息\n",
    "    src = [src_mapping[index] for index in df[src_index_col]]\n",
    "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
    "    # 注意这里edge_index维度为[2,边数]\n",
    "    edge_index = torch.tensor([src, dst])\n",
    "    # 边的属性信息\n",
    "    edge_attr = None\n",
    "    # 如果嵌入器非空\n",
    "    if encoders is not None:\n",
    "        edge_attrs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
    "        edge_attr = torch.cat(edge_attrs, dim=-1)\n",
    " \n",
    "    return edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取二分图边的信息\n",
    "edge_index, edge_label = load_edge_csv(\n",
    "    rating_path,\n",
    "    # 二分图左边是用户\n",
    "    src_index_col='userId',\n",
    "    src_mapping=user_mapping,\n",
    "    # 右边是电影\n",
    "    dst_index_col='movieId',\n",
    "    dst_mapping=movie_mapping,\n",
    "    encoders={'rating': IdentityEncoder(dtype=torch.long)},\n",
    ")\n",
    "# 将二分图中的边命名为('user', 'rates', 'movie')\n",
    "data['user', 'rates', 'movie'].edge_index = edge_index\n",
    "data['user', 'rates', 'movie'].edge_label = edge_label\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 到此我们的异质图(这里是一个二分图)数据集就构建完毕了\n",
    "# 下面进一步将其转换为一个真正可以进行训练的数据集\n",
    "# 转换为无向图\n",
    "data = ToUndirected()(data)\n",
    "# 删除相反方向边的属性信息，因为没有电影对用户的评分数据\n",
    "del data['movie', 'rev_rates', 'user'].edge_label\n",
    " \n",
    "# 按照一定比例分割数据集为训练集、测试集、验证集\n",
    "transform = RandomLinkSplit(\n",
    "    num_val=0.05,\n",
    "    num_test=0.1,\n",
    "    # 负采样比率\n",
    "    # 不用负采样，全部输入进行训练\n",
    "    neg_sampling_ratio=0.0,\n",
    "    # 告诉PyG边的连接关系\n",
    "    edge_types=[('user', 'rates', 'movie')],\n",
    "    rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
    ")\n",
    "# 分割数据集\n",
    "train_data, val_data, test_data = transform(data)\n",
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1084607fb1ec85c20c00d1b5b4f2e0b7627b79be1f5395c4e028471685aafe8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
